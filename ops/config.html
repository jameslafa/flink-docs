<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink 1.4-SNAPSHOT Documentation: Configuration</title>
    <link rel="shortcut icon" href="//ci.apache.org/projects/flink/flink-docs-release-1.4/page/favicon.ico" type="image/x-icon">
    <link rel="icon" href="//ci.apache.org/projects/flink/flink-docs-release-1.4/page/favicon.ico" type="image/x-icon">

    <!-- Bootstrap -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css">
    <link rel="stylesheet" href="//ci.apache.org/projects/flink/flink-docs-release-1.4/page/css/flink.css">
    <link rel="stylesheet" href="//ci.apache.org/projects/flink/flink-docs-release-1.4/page/css/syntax.css">
    <link rel="stylesheet" href="//ci.apache.org/projects/flink/flink-docs-release-1.4/page/css/codetabs.css">
    <link rel="stylesheet" href="//ci.apache.org/projects/flink/flink-docs-release-1.4/page/font-awesome/css/font-awesome.min.css">
    
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
    

    <!-- Main content. -->
    <div class="container">
      
      <div class="row">
        <div class="col-lg-3" id="sidenavcol">
          







  
    
    
    
      
    
  

  
    
    
    
      









  





<div class="sidenav-logo">
  <p><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4"><img class="bottom" alt="Apache Flink" src="//ci.apache.org/projects/flink/flink-docs-release-1.4/page/img/navbar-brand-logo.jpg"></a> v1.4-SNAPSHOT</p>
</div>
<ul id="sidenav">

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/index.html"><i class="fa fa-home title" aria-hidden="true"></i> Home</a></li>
    
  

  
    

    
      
    

    
    
    

    <hr class="section-break"></hr>

    
    
      
      
        
        
<li><a href="#collapse-2" data-toggle="collapse"><i class="fa fa-map-o title appetizer" aria-hidden="true"></i> Concepts <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-2"><ul>
  
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/concepts/programming-model.html">Programming Model</a></li>
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/concepts/runtime.html">Distributed Runtime</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/quickstart/setup_quickstart.html"><i class="fa fa-power-off title appetizer" aria-hidden="true"></i> Quickstart</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-7" data-toggle="collapse"><i class="fa fa-file-code-o title appetizer" aria-hidden="true"></i> Examples <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-7"><ul>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/examples/index.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/quickstart/run_example_quickstart.html">Monitoring Wikipedia Edits</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/batch/examples.html">Batch Examples</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-11" data-toggle="collapse"><i class="fa fa-book title appetizer" aria-hidden="true"></i> Cookbook <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-11"><ul>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/cookbook/index.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/cookbook/stream-enrichment-join.html">Stream Enrichment Join</a></li>
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/cookbook/pattern-detection.html">Pattern Detection with CEP</a></li>
      
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    <hr class="section-break"></hr>

    
    
      
      
        
        
<li><a href="#collapse-15" data-toggle="collapse"><i class="fa fa-cogs title maindish" aria-hidden="true"></i> Project Setup <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-15"><ul>
  
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/quickstart/java_api_quickstart.html">Sample Project in Java</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/quickstart/scala_api_quickstart.html">Sample Project in Scala</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/linking_with_flink.html">Linking with Flink</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/internals/ide_setup.html">IDE Setup</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/scala_shell.html">Scala REPL</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/linking.html">Linking with Optional Modules</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/start/flink_on_windows.html">Running Flink on Windows</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/start/building.html">Building Flink from Source</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-25" data-toggle="collapse"><i class="fa fa-code title maindish" aria-hidden="true"></i> Application Development <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-25"><ul>
  
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-26" data-toggle="collapse">Basic API Concepts <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-26"><ul>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/api_concepts.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/scala_api_extensions.html">Scala API Extensions</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/java8.html">Java 8</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-30" data-toggle="collapse">Streaming (DataStream API) <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-30"><ul>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/datastream_api.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-31" data-toggle="collapse">Event Time <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-31"><ul>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/event_time.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/event_timestamps_watermarks.html">Generating Timestamps / Watermarks</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/event_timestamp_extractors.html">Pre-defined Timestamp Extractors / Watermark Emitters</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-35" data-toggle="collapse">State & Fault Tolerance <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-35"><ul>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/stream/state/index.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/stream/state/state.html">Working with State</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/stream/state/checkpointing.html">Checkpointing</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/stream/state/queryable_state.html">Queryable State</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/stream/state/state_backends.html">State Backends</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/stream/state/custom_serialization.html">Custom Serialization</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-42" data-toggle="collapse">Operators <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-42"><ul>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/stream/operators/index.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/stream/operators/windows.html">Windows</a></li>
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/stream/operators/process_function.html">Process Function</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/stream/operators/asyncio.html">Async I/O</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-47" data-toggle="collapse">Connectors <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-47"><ul>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/connectors/index.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/connectors/guarantees.html">Fault Tolerance Guarantees</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/connectors/kafka.html">Kafka</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/connectors/cassandra.html">Cassandra</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/connectors/kinesis.html">Kinesis</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/connectors/elasticsearch.html">Elasticsearch</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/connectors/filesystem_sink.html">Rolling File Sink</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/connectors/rabbitmq.html">RabbitMQ</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/connectors/nifi.html">NiFi</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/connectors/twitter.html">Twitter</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/stream/side_output.html">Side Outputs</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/stream/testing.html">Testing</a></li>
      
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-61" data-toggle="collapse">Batch (DataSet API) <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-61"><ul>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/batch/index.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/batch/dataset_transformations.html">Transformations</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/batch/iterations.html">Iterations</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/batch/zip_elements_guide.html">Zipping Elements</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/batch/fault_tolerance.html">Fault Tolerance</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/batch/python.html">Python API</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/batch/connectors.html">Connectors</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/batch/hadoop_compatibility.html">Hadoop Compatibility</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/local_execution.html">Local Execution</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/cluster_execution.html">Cluster Execution</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-72" data-toggle="collapse">Table API & SQL <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-72"><ul>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/table/index.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/table/common.html">Concepts & Common API</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/table/streaming.html">Streaming Concepts</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/table/tableApi.html">Table API</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/table/sql.html">SQL</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/table/sourceSinks.html">Table Sources & Sinks</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/table/udfs.html">User-defined Functions</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-80" data-toggle="collapse">Data Types & Serialization <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-80"><ul>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/types_serialization.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/custom_serializers.html">Custom Serializers</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-83" data-toggle="collapse">Managing Execution <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-83"><ul>
  
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/execution_configuration.html">Execution Configuration</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/packaging.html">Program Packaging</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/parallel.html">Parallel Execution</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/execution_plans.html">Execution Plans</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/restart_strategies.html">Restart Strategies</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-90" data-toggle="collapse">Libraries <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-90"><ul>
  
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/libs/cep.html">Event Processing (CEP)</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/libs/storm_compatibility.html">Storm Compatibility</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-93" data-toggle="collapse">Graphs: Gelly <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-93"><ul>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/libs/gelly/index.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/libs/gelly/graph_api.html">Graph API</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/libs/gelly/iterative_graph_processing.html">Iterative Graph Processing</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/libs/gelly/library_methods.html">Library Methods</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/libs/gelly/graph_algorithms.html">Graph Algorithms</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/libs/gelly/graph_generators.html">Graph Generators</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/libs/gelly/bipartite_graph.html">Bipartite Graph</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-101" data-toggle="collapse">Machine Learning <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-101"><ul>
  <li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/libs/ml/index.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/libs/ml/quickstart.html">Quickstart</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/libs/ml/multiple_linear_regression.html">Multiple Linear Regression</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/libs/ml/cross_validation.html">Cross Validation</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/libs/ml/distance_metrics.html">Distance Metrics</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/libs/ml/knn.html">k-Nearest Neighbors Join</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/libs/ml/min_max_scaler.html">MinMax Scaler</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/libs/ml/contribution_guide.html">How to Contribute</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/libs/ml/pipelines.html">Pipelines</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/libs/ml/polynomial_features.html">Polynomial Features</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/libs/ml/als.html">ALS</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/libs/ml/sos.html">Stochastic Outlier Selection</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/libs/ml/standard_scaler.html">Standard Scaler</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/libs/ml/svm.html">SVM using CoCoA</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/best_practices.html">Best Practices</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/migration.html">API Migration Guides</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-120" data-toggle="collapse" class="active"><i class="fa fa-sliders title maindish" aria-hidden="true"></i> Deployment & Operations</a><div class="collapse in" id="collapse-120"><ul>
  
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-121" data-toggle="collapse">Clusters & Deployment <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-121"><ul>
  
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/ops/deployment/cluster_setup.html">Standalone Cluster</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/ops/deployment/yarn_setup.html">YARN</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/ops/deployment/mesos.html">Mesos</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/ops/deployment/docker.html">Docker</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/ops/deployment/kubernetes.html">Kubernetes</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/ops/deployment/aws.html">AWS</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/ops/deployment/gce_setup.html">Google Compute Engine</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/ops/deployment/mapr_setup.html">MapR</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/ops/jobmanager_high_availability.html">High Availability (HA)</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-132" data-toggle="collapse">State & Fault Tolerance <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-132"><ul>
  
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/ops/state/checkpoints.html">Checkpoints</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/ops/state/savepoints.html">Savepoints</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/ops/state/state_backends.html">State Backends</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/ops/state/large_state_tuning.html">Tuning Checkpoints and Large State</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/ops/config.html" class="active">Configuration</a></li>
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/ops/production_ready.html">Production Readiness Checklist</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/ops/cli.html">CLI</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/ops/security-kerberos.html">Kerberos</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/ops/security-ssl.html">SSL Setup</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/ops/upgrading.html">Upgrading Applications and Flink Versions</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-145" data-toggle="collapse"><i class="fa fa-bug title maindish" aria-hidden="true"></i> Debugging & Monitoring <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-145"><ul>
  
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/monitoring/metrics.html">Metrics</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/monitoring/logging.html">Logging</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/monitoring/historyserver.html">History Server</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/monitoring/checkpoint_monitoring.html">Monitoring Checkpointing</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/monitoring/back_pressure.html">Monitoring Back Pressure</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/monitoring/rest_api.html">Monitoring REST API</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/monitoring/debugging_event_time.html">Debugging Windows & Event Time</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/monitoring/debugging_classloading.html">Debugging Classloading</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/monitoring/application_profiling.html">Application Profiling</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    
      
    

    
    
    

    <hr class="section-break"></hr>

    
    
      
      
        
        
<li><a href="#collapse-156" data-toggle="collapse"><i class="fa fa-book title dessert" aria-hidden="true"></i> Internals <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-156"><ul>
  
        
        
        

        
        
      
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/internals/components.html">Component Stack</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/internals/stream_checkpointing.html">Fault Tolerance for Data Streaming</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/internals/job_scheduling.html">Jobs and Scheduling</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/internals/task_lifecycle.html">Task Lifecycle</a></li>
    
  

  
    

    
      
    

    
    
    

    

    
    
<li><a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/internals/filesystems.html">File Systems</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    
      
  <li class="divider"></li>
  <li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/api/java"><i class="fa fa-external-link title" aria-hidden="true"></i> Javadocs</a></li>
  <li><a href="http://flink.apache.org"><i class="fa fa-external-link title" aria-hidden="true"></i> Project Page</a></li>
</ul>

<div class="sidenav-search-box">
  <form class="navbar-form" role="search" action="//ci.apache.org/projects/flink/flink-docs-release-1.4/search-results.html">
    <div class="form-group">
      <input type="text" class="form-control" size="16px" name="q" placeholder="Search">
    </div>
    <button type="submit" class="btn btn-default">Go</button>
  </form>
</div>

<div class="sidenav-versions">
  <div class="dropdown">
    <button class="btn btn-default dropdown-toggle" type="button" data-toggle="dropdown">Pick Docs Version
    <span class="caret"></span></button>
    <ul class="dropdown-menu">
      
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.3">v1.3</a></li>
      
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.2">v1.2</a></li>
      
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.1">v1.1</a></li>
      
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.0">v1.0</a></li>
      
    </ul>
  </div>
</div>

        </div>
        <div class="col-lg-9 content" id="contentcol">
          

          





  
  
    
    
      
    
  

  
  
    
    
      



<ol class="breadcrumb">

  
  
    <li><i class="fa fa-sliders title maindish" aria-hidden="true"></i> Deployment & Operations</li>
  

  
  
    <li class="active">Configuration</li>
  

</ol>

<h1>Configuration</h1>




<p><strong>For single-node setups Flink is ready to go out of the box and you don’t need to change the default configuration to get started.</strong></p>

<p>The out of the box configuration will use your default Java installation. You can manually set the environment variable <code>JAVA_HOME</code> or the configuration key <code>env.java.home</code> in <code>conf/flink-conf.yaml</code> if you want to manually override the Java runtime to use.</p>

<p>This page lists the most common options that are typically needed to set up a well performing (distributed) installation. In addition a full list of all available configuration parameters is listed here.</p>

<p>All configuration is done in <code>conf/flink-conf.yaml</code>, which is expected to be a flat collection of <a href="http://www.yaml.org/spec/1.2/spec.html">YAML key value pairs</a> with format <code>key: value</code>.</p>

<p>The system and run scripts parse the config at startup time. Changes to the configuration file require restarting the Flink JobManager and TaskManagers.</p>

<p>The configuration files for the TaskManagers can be different, Flink does not assume uniform machines in the cluster.</p>

<ul id="markdown-toc">
  <li><a href="#common-options" id="markdown-toc-common-options">Common Options</a></li>
  <li><a href="#advanced-options" id="markdown-toc-advanced-options">Advanced Options</a>    <ul>
      <li><a href="#compute" id="markdown-toc-compute">Compute</a></li>
      <li><a href="#managed-memory" id="markdown-toc-managed-memory">Managed Memory</a></li>
      <li><a href="#memory-and-performance-debugging" id="markdown-toc-memory-and-performance-debugging">Memory and Performance Debugging</a></li>
      <li><a href="#kerberos-based-security" id="markdown-toc-kerberos-based-security">Kerberos-based Security</a></li>
      <li><a href="#other" id="markdown-toc-other">Other</a></li>
    </ul>
  </li>
  <li><a href="#full-reference" id="markdown-toc-full-reference">Full Reference</a>    <ul>
      <li><a href="#hdfs" id="markdown-toc-hdfs">HDFS</a></li>
      <li><a href="#jobmanager-amp-taskmanager" id="markdown-toc-jobmanager-amp-taskmanager">JobManager &amp; TaskManager</a></li>
      <li><a href="#distributed-coordination-via-akka" id="markdown-toc-distributed-coordination-via-akka">Distributed Coordination (via Akka)</a></li>
      <li><a href="#ssl-settings" id="markdown-toc-ssl-settings">SSL Settings</a></li>
      <li><a href="#network-communication-via-netty" id="markdown-toc-network-communication-via-netty">Network communication (via Netty)</a></li>
      <li><a href="#web-frontend" id="markdown-toc-web-frontend">Web Frontend</a></li>
      <li><a href="#file-systems" id="markdown-toc-file-systems">File Systems</a></li>
      <li><a href="#compileroptimizer" id="markdown-toc-compileroptimizer">Compiler/Optimizer</a></li>
      <li><a href="#runtime-algorithms" id="markdown-toc-runtime-algorithms">Runtime Algorithms</a></li>
      <li><a href="#resource-manager" id="markdown-toc-resource-manager">Resource Manager</a></li>
      <li><a href="#yarn" id="markdown-toc-yarn">YARN</a></li>
      <li><a href="#mesos" id="markdown-toc-mesos">Mesos</a></li>
      <li><a href="#high-availability-ha" id="markdown-toc-high-availability-ha">High Availability (HA)</a></li>
      <li><a href="#kerberos-based-security-1" id="markdown-toc-kerberos-based-security-1">Kerberos-based Security</a></li>
      <li><a href="#environment" id="markdown-toc-environment">Environment</a></li>
      <li><a href="#queryable-state" id="markdown-toc-queryable-state">Queryable State</a></li>
      <li><a href="#metrics" id="markdown-toc-metrics">Metrics</a></li>
      <li><a href="#history-server" id="markdown-toc-history-server">History Server</a></li>
    </ul>
  </li>
  <li><a href="#background" id="markdown-toc-background">Background</a>    <ul>
      <li><a href="#configuring-the-network-buffers" id="markdown-toc-configuring-the-network-buffers">Configuring the Network Buffers</a></li>
      <li><a href="#configuring-temporary-io-directories" id="markdown-toc-configuring-temporary-io-directories">Configuring Temporary I/O Directories</a></li>
      <li><a href="#configuring-taskmanager-processing-slots" id="markdown-toc-configuring-taskmanager-processing-slots">Configuring TaskManager processing slots</a></li>
    </ul>
  </li>
</ul>

<h2 id="common-options">Common Options</h2>

<ul>
  <li>
    <p><code>env.java.home</code>: The path to the Java installation to use (DEFAULT: system’s default Java installation, if found). Needs to be specified if the startup scripts fail to automatically resolve the java home directory. Can be specified to point to a specific java installation or version. If this option is not specified, the startup scripts also evaluate the <code>$JAVA_HOME</code> environment variable.</p>
  </li>
  <li>
    <p><code>env.java.opts</code>: Set custom JVM options. This value is respected by Flink’s start scripts, both JobManager and
TaskManager, and Flink’s YARN client. This can be used to set different garbage collectors or to include remote
debuggers into the JVMs running Flink’s services. Enclosing options in double quotes delays parameter substitution
allowing access to variables from Flink’s startup scripts. Use <code>env.java.opts.jobmanager</code> and <code>env.java.opts.taskmanager</code>
for JobManager or TaskManager-specific options, respectively.</p>
  </li>
  <li>
    <p><code>env.java.opts.jobmanager</code>: JobManager-specific JVM options. These are used in addition to the regular <code>env.java.opts</code>.</p>
  </li>
  <li>
    <p><code>env.java.opts.taskmanager</code>: TaskManager-specific JVM options. These are used in addition to the regular <code>env.java.opts</code>.</p>
  </li>
  <li>
    <p><code>jobmanager.rpc.address</code>: The external address of the JobManager, which is the master/coordinator of the distributed system (DEFAULT: localhost). <strong>Note:</strong> The address (host name or IP) should be accessible by all nodes including the client.</p>
  </li>
  <li>
    <p><code>jobmanager.rpc.port</code>: The port number of the JobManager (DEFAULT: 6123).</p>
  </li>
  <li>
    <p><code>jobmanager.heap.mb</code>: JVM heap size (in megabytes) for the JobManager. You may have to increase the heap size for the JobManager if you are running very large applications (with many operators), or if you are keeping a long history of them.</p>
  </li>
  <li>
    <p><code>taskmanager.heap.mb</code>: JVM heap size (in megabytes) for the TaskManagers, which are the parallel workers of the system. In contrast to Hadoop, Flink runs operators (e.g., join, aggregate) and user-defined functions (e.g., Map, Reduce, CoGroup) inside the TaskManager (including sorting/hashing/caching), so this value should be as large as possible. If the cluster is exclusively running Flink, the total amount of available memory per machine minus some memory for the operating system (maybe 1-2 GB) is a good value. On YARN setups, this value is automatically configured to the size of the TaskManager’s YARN container, minus a certain tolerance value.</p>
  </li>
  <li>
    <p><code>taskmanager.numberOfTaskSlots</code>: The number of parallel operator or user function instances that a single TaskManager can run (DEFAULT: 1). If this value is larger than 1, a single TaskManager takes multiple instances of a function or operator. That way, the TaskManager can utilize multiple CPU cores, but at the same time, the available memory is divided between the different operator or function instances. This value is typically proportional to the number of physical CPU cores that the TaskManager’s machine has (e.g., equal to the number of cores, or half the number of cores). <a href="config.html#configuring-taskmanager-processing-slots">More about task slots</a>.</p>
  </li>
  <li>
    <p><code>parallelism.default</code>: The default parallelism to use for programs that have no parallelism specified. (DEFAULT: 1). For setups that have no concurrent jobs running, setting this value to NumTaskManagers * NumSlotsPerTaskManager will cause the system to use all available execution resources for the program’s execution. <strong>Note</strong>: The default parallelism can be overwriten for an entire job by calling <code>setParallelism(int parallelism)</code> on the <code>ExecutionEnvironment</code> or by passing <code>-p &lt;parallelism&gt;</code> to the Flink Command-line frontend. It can be overwritten for single transformations by calling <code>setParallelism(int
parallelism)</code> on an operator. See <a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/parallel.html">Parallel Execution</a> for more information about parallelism.</p>
  </li>
  <li>
    <p><code>fs.default-scheme</code>: The default filesystem scheme to be used, with the necessary authority to contact, e.g. the host:port of the NameNode in the case of HDFS (if needed).
By default, this is set to <code>file:///</code> which points to the local filesystem. This means that the local
filesystem is going to be used to search for user-specified files <strong>without</strong> an explicit scheme
definition. As another example, if this is set to <code>hdfs://localhost:9000/</code>, then a user-specified file path
without explicit scheme definition, such as <code>/user/USERNAME/in.txt</code>, is going to be transformed into
<code>hdfs://localhost:9000/user/USERNAME/in.txt</code>. This scheme is used <strong>ONLY</strong> if no other scheme is specified (explicitly) in the user-provided <code>URI</code>.</p>
  </li>
  <li>
    <p><code>fs.hdfs.hadoopconf</code>: The absolute path to the Hadoop File System’s (HDFS) configuration <strong>directory</strong> (OPTIONAL VALUE). Specifying this value allows programs to reference HDFS files using short URIs (<code>hdfs:///path/to/files</code>, without including the address and port of the NameNode in the file URI). Without this option, HDFS files can be accessed, but require fully qualified URIs like <code>hdfs://address:port/path/to/files</code>. This option also causes file writers to pick up the HDFS’s default values for block sizes and replication factors. Flink will look for the “core-site.xml” and “hdfs-site.xml” files in the specified directory.</p>
  </li>
</ul>

<h2 id="advanced-options">Advanced Options</h2>

<h3 id="compute">Compute</h3>

<ul>
  <li><code>taskmanager.compute.numa</code>: When enabled a TaskManager is started on each NUMA node for each worker listed in <em>conf/slaves</em> (DEFAULT: false). Note: only supported when deploying Flink as a standalone cluster.</li>
</ul>

<h3 id="managed-memory">Managed Memory</h3>

<p>By default, Flink allocates a fraction of <code>0.7</code> of the free memory (total memory configured via <code>taskmanager.heap.mb</code> minus memory used for network buffers) for its managed memory. Managed memory helps Flink to run the batch operators efficiently. It prevents <code>OutOfMemoryException</code>s because Flink knows how much memory it can use to execute operations. If Flink runs out of managed memory, it utilizes disk space. Using managed memory, some operations can be performed directly on the raw data without having to deserialize the data to convert it into Java objects. All in all, managed memory improves the robustness and speed of the system.</p>

<p>The default fraction for managed memory can be adjusted using the <code>taskmanager.memory.fraction</code> parameter. An absolute value may be set using <code>taskmanager.memory.size</code> (overrides the fraction parameter). If desired, the managed memory may be allocated outside the JVM heap. This may improve performance in setups with large memory sizes.</p>

<ul>
  <li>
    <p><code>taskmanager.memory.size</code>: The amount of memory (in megabytes) that the task manager reserves on-heap or off-heap (depending on <code>taskmanager.memory.off-heap</code>) for sorting, hash tables, and caching of intermediate results. If unspecified (-1), the memory manager will take a fixed ratio with respect to the size of the task manager JVM as specified by <code>taskmanager.memory.fraction</code>. (DEFAULT: -1)</p>
  </li>
  <li>
    <p><code>taskmanager.memory.fraction</code>: The relative amount of memory (with respect to <code>taskmanager.heap.mb</code>, after subtracting the amount of memory used by network buffers) that the task manager reserves for sorting, hash tables, and caching of intermediate results. For example, a value of <code>0.8</code> means that a task manager reserves 80% of its memory (on-heap or off-heap depending on <code>taskmanager.memory.off-heap</code>) for internal data buffers, leaving 20% of free memory for the task manager’s heap for objects created by user-defined functions. (DEFAULT: 0.7) This parameter is only evaluated, if <code>taskmanager.memory.size</code> is not set.</p>
  </li>
  <li>
    <p><code>taskmanager.memory.off-heap</code>: If set to <code>true</code>, the task manager allocates memory which is used for sorting, hash tables, and caching of intermediate results outside of the JVM heap. For setups with larger quantities of memory, this can improve the efficiency of the operations performed on the memory (DEFAULT: false).</p>
  </li>
  <li>
    <p><code>taskmanager.memory.segment-size</code>: The size of memory buffers used by the memory manager and the network stack in bytes (DEFAULT: 32768 (= 32 KiBytes)).</p>
  </li>
  <li>
    <p><code>taskmanager.memory.preallocate</code>: Can be either of <code>true</code> or <code>false</code>. Specifies whether task managers should allocate all managed memory when starting up. (DEFAULT: false). When <code>taskmanager.memory.off-heap</code> is set to <code>true</code>, then it is advised that this configuration is also set to <code>true</code>.  If this configuration is set to <code>false</code> cleaning up of the allocated offheap memory happens only when the configured JVM parameter MaxDirectMemorySize is reached by triggering a full GC. <strong>Note:</strong> For streaming setups, we highly recommend to set this value to <code>false</code> as the core state backends currently do not use the managed memory.</p>
  </li>
</ul>

<h3 id="memory-and-performance-debugging">Memory and Performance Debugging</h3>

<p>These options are useful for debugging a Flink application for memory and garbage collection related issues, such as performance and out-of-memory process kills or exceptions.</p>

<ul>
  <li>
    <p><code>taskmanager.debug.memory.startLogThread</code>: Causes the TaskManagers to periodically log memory and Garbage collection statistics. The statistics include current heap-, off-heap, and other memory pool utilization, as well as the time spent on garbage collection, by heap memory pool.</p>
  </li>
  <li>
    <p><code>taskmanager.debug.memory.logIntervalMs</code>: The interval (in milliseconds) in which the TaskManagers log the memory and garbage collection statistics. Only has an effect, if <code>taskmanager.debug.memory.startLogThread</code> is set to true.</p>
  </li>
</ul>

<h3 id="kerberos-based-security">Kerberos-based Security</h3>

<p>Flink supports Kerberos authentication for the following services:</p>

<ul>
  <li>Hadoop Components, such as HDFS, YARN, or HBase <em>(version 2.6.1 and above; all other versions have critical bugs which might fail the Flink job unexpectedly)</em>.</li>
  <li>Kafka Connectors <em>(version 0.9+ and above)</em>.</li>
  <li>Zookeeper</li>
</ul>

<p>Configuring Flink for Kerberos security involves three aspects, explained separately in the following sub-sections.</p>

<h5 id="providing-the-cluster-with-a-kerberos-credential-ie-a-keytab-or-a-ticket-via-kinit">1. Providing the cluster with a Kerberos credential (i.e. a keytab or a ticket via <code>kinit</code>)</h5>

<p>To provide the cluster with a Kerberos credential, Flink supports using a Kerberos keytab file or ticket caches managed by <code>kinit</code>.</p>

<ul>
  <li>
    <p><code>security.kerberos.login.use-ticket-cache</code>: Indicates whether to read from your Kerberos ticket cache (default: <code>true</code>).</p>
  </li>
  <li>
    <p><code>security.kerberos.login.keytab</code>: Absolute path to a Kerberos keytab file that contains the user credentials.</p>
  </li>
  <li>
    <p><code>security.kerberos.login.principal</code>: Kerberos principal name associated with the keytab.</p>
  </li>
</ul>

<p>If both <code>security.kerberos.login.keytab</code> and <code>security.kerberos.login.principal</code> have values provided, keytabs will be used for authentication.
It is preferable to use keytabs for long-running jobs, to avoid ticket expiration issues.   If you prefer to use the ticket cache,
talk to your administrator about increasing the Hadoop delegation token lifetime.</p>

<p>Note that authentication using ticket caches is only supported when deploying Flink as a standalone cluster or on YARN.</p>

<h5 id="making-the-kerberos-credential-available-to-components-and-connectors-as-needed">2. Making the Kerberos credential available to components and connectors as needed</h5>

<p>For Hadoop components, Flink will automatically detect if the configured Kerberos credentials should be used when connecting to HDFS, HBase, and other Hadoop components depending on whether Hadoop security is enabled (in <code>core-site.xml</code>).</p>

<p>For any connector or component that uses a JAAS configuration file, make the Kerberos credentials available to them by configuring JAAS login contexts for each one respectively, using the following configuration:</p>

<ul>
  <li><code>security.kerberos.login.contexts</code>: A comma-separated list of login contexts to provide the Kerberos credentials to (for example, <code>Client,KafkaClient</code> to use the credentials for ZooKeeper authentication and for Kafka authentication).</li>
</ul>

<p>This allows enabling Kerberos authentication for different connectors or components independently. For example, you can enable Hadoop security without necessitating the use of Kerberos for ZooKeeper, or vice versa.</p>

<p>You may also provide a static JAAS configuration file using the mechanisms described in the <a href="http://docs.oracle.com/javase/7/docs/technotes/guides/security/jgss/tutorials/LoginConfigFile.html">Java SE Documentation</a>, whose entries will override those produced by the above configuration option.</p>

<h5 id="configuring-the-component-andor-connector-to-use-kerberos-authentication">3. Configuring the component and/or connector to use Kerberos authentication</h5>

<p>Finally, be sure to configure the connector within your Flink program or component as necessary to use Kerberos authentication.</p>

<p>Below is a list of currently first-class supported connectors or components by Flink for Kerberos authentication:</p>

<ul>
  <li>
    <p>Kafka: see <a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/connectors/kafka.html#enabling-kerberos-authentication-for-versions-above-09-only">here</a> for details on configuring the Kafka connector to use Kerberos authentication.</p>
  </li>
  <li>
    <p>Zookeeper (for HA): see <a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/ops/jobmanager_high_availability.html#configuring-for-zookeeper-security">here</a> for details on Zookeeper security configuration to work with the Kerberos-based security configurations mentioned here.</p>
  </li>
</ul>

<p>For more information on how Flink security internally setups Kerberos authentication, please see <a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/ops/security-kerberos.html">here</a>.</p>

<h3 id="other">Other</h3>

<ul>
  <li>
    <p><code>taskmanager.tmp.dirs</code>: The directory for temporary files, or a list of directories separated by the system’s directory delimiter (for example ‘:’ (colon) on Linux/Unix). If multiple directories are specified, then the temporary files will be distributed across the directories in a round-robin fashion. The I/O manager component will spawn one reading and one writing thread per directory. A directory may be listed multiple times to have the I/O manager use multiple threads for it (for example if it is physically stored on a very fast disc or RAID) (DEFAULT: The system’s tmp dir).</p>
  </li>
  <li>
    <p><code>taskmanager.log.path</code>: The config parameter defining the taskmanager log file location</p>
  </li>
  <li>
    <p><code>jobmanager.web.address</code>: Address of the JobManager’s web interface (DEFAULT: anyLocalAddress()).</p>
  </li>
  <li>
    <p><code>jobmanager.web.port</code>: Port of the JobManager’s web interface (DEFAULT: 8081).</p>
  </li>
  <li>
    <p><code>jobmanager.web.tmpdir</code>: This configuration parameter allows defining the Flink web directory to be used by the web interface. The web interface
will copy its static files into the directory. Also uploaded job jars are stored in the directory if not overridden. By default, the temporary directory is used.</p>
  </li>
  <li>
    <p><code>jobmanager.web.upload.dir</code>: The config parameter defining the directory for uploading the job jars. If not specified a dynamic directory
will be used under the directory specified by jobmanager.web.tmpdir.</p>
  </li>
  <li>
    <p><code>fs.overwrite-files</code>: Specifies whether file output writers should overwrite existing files by default. Set to <em>true</em> to overwrite by default, <em>false</em> otherwise. (DEFAULT: false)</p>
  </li>
  <li>
    <p><code>fs.output.always-create-directory</code>: File writers running with a parallelism larger than one create a directory for the output file path and put the different result files (one per parallel writer task) into that directory. If this option is set to <em>true</em>, writers with a parallelism of 1 will also create a directory and place a single result file into it. If the option is set to <em>false</em>, the writer will directly create the file directly at the output path, without creating a containing directory. (DEFAULT: false)</p>
  </li>
  <li>
    <p><code>taskmanager.network.memory.fraction</code>: Fraction of JVM memory to use for network buffers. This determines how many streaming data exchange channels a TaskManager can have at the same time and how well buffered the channels are. If a job is rejected or you get a warning that the system has not enough buffers available, increase this value or the min/max values below. (DEFAULT: 0.1)</p>
  </li>
  <li>
    <p><code>taskmanager.network.memory.min</code>: Minimum memory size for network buffers in bytes (DEFAULT: 64 MB)</p>
  </li>
  <li>
    <p><code>taskmanager.network.memory.max</code>: Maximum memory size for network buffers in bytes (DEFAULT: 1 GB)</p>
  </li>
  <li><code>state.backend</code>: The backend that will be used to store operator state checkpoints if checkpointing is enabled. Supported backends:
    <ul>
      <li><code>jobmanager</code>: In-memory state, backup to JobManager’s/ZooKeeper’s memory. Should be used only for minimal state (Kafka offsets) or testing and local debugging.</li>
      <li><code>filesystem</code>: State is in-memory on the TaskManagers, and state snapshots are stored in a file system. Supported are all filesystems supported by Flink, for example HDFS, S3, …</li>
    </ul>
  </li>
  <li>
    <p><code>state.backend.fs.checkpointdir</code>: Directory for storing checkpoints in a Flink supported filesystem. Note: State backend must be accessible from the JobManager, use <code>file://</code> only for local setups.</p>
  </li>
  <li>
    <p><code>state.backend.rocksdb.checkpointdir</code>:  The local directory for storing RocksDB files, or a list of directories separated by the systems directory delimiter (for example ‘:’ (colon) on Linux/Unix). (DEFAULT value is <code>taskmanager.tmp.dirs</code>)</p>
  </li>
  <li>
    <p><code>state.checkpoints.dir</code>: The target directory for meta data of <a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/ops/state/checkpoints.html#externalized-checkpoints">externalized checkpoints</a>.</p>
  </li>
  <li>
    <p><code>state.checkpoints.num-retained</code>: The number of completed checkpoint instances to retain. Having more than one allows recovery fallback to an earlier checkpoints if the latest checkpoint is corrupt. (Default: 1)</p>
  </li>
  <li>
    <p><code>high-availability.zookeeper.storageDir</code>: Required for HA. Directory for storing JobManager metadata; this is persisted in the state backend and only a pointer to this state is stored in ZooKeeper. Exactly like the checkpoint directory it must be accessible from the JobManager and a local filesystem should only be used for local deployments. Previously this key was named <code>recovery.zookeeper.storageDir</code>.</p>
  </li>
  <li>
    <p><code>blob.storage.directory</code>: Directory for storing blobs (such as user JARs) on the TaskManagers.</p>
  </li>
  <li>
    <p><code>blob.service.cleanup.interval</code>: Cleanup interval (in seconds) of the blob caches (DEFAULT: 1 hour).
Whenever a job is not referenced at the cache anymore, we set a TTL and let the periodic cleanup task
(executed every <code>blob.service.cleanup.interval</code> seconds) remove its blob files after this TTL has passed.
This means that a blob will be retained at most <tt>2 * <code>blob.service.cleanup.interval</code></tt> seconds after
not being referenced anymore. Therefore, a recovery still has the chance to use existing files rather
than to download them again.</p>
  </li>
  <li>
    <p><code>blob.server.port</code>: Port definition for the blob server (serving user JARs) on the TaskManagers. By default the port is set to 0, which means that the operating system is picking an ephemeral port. Flink also accepts a list of ports (“50100,50101”), ranges (“50100-50200”) or a combination of both. It is recommended to set a range of ports to avoid collisions when multiple JobManagers are running on the same machine.</p>
  </li>
  <li>
    <p><code>blob.service.ssl.enabled</code>: Flag to enable ssl for the blob client/server communication. This is applicable only when the global ssl flag security.ssl.enabled is set to true (DEFAULT: true).</p>
  </li>
  <li><code>restart-strategy</code>: Default <a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/restart_strategies.html">restart strategy</a> to use in case no
restart strategy has been specified for the job.
The options are:
    <ul>
      <li>fixed delay strategy: <code>fixed-delay</code>.</li>
      <li>failure rate strategy: <code>failure-rate</code>.</li>
      <li>no restarts: <code>none</code></li>
    </ul>

    <p>Default value is <code>none</code> unless checkpointing is enabled for the job in which case the default is <code>fixed-delay</code> with <code>Integer.MAX_VALUE</code> restart attempts and <code>10s</code> delay.</p>
  </li>
  <li>
    <p><code>restart-strategy.fixed-delay.attempts</code>: Number of restart attempts, used if the default restart strategy is set to “fixed-delay”.
Default value is 1, unless “fixed-delay” was activated by enabling checkpoints, in which case the default is <code>Integer.MAX_VALUE</code>.</p>
  </li>
  <li>
    <p><code>restart-strategy.fixed-delay.delay</code>: Delay between restart attempts, used if the default restart strategy is set to “fixed-delay”.
Default value is the <code>akka.ask.timeout</code>, unless “fixed-delay” was activated by enabling checkpoints, in which case
the default is 10s.</p>
  </li>
  <li>
    <p><code>restart-strategy.failure-rate.max-failures-per-interval</code>: Maximum number of restarts in given time interval before failing a job in “failure-rate” strategy.
Default value is 1.</p>
  </li>
  <li>
    <p><code>restart-strategy.failure-rate.failure-rate-interval</code>: Time interval for measuring failure rate in “failure-rate” strategy.
Default value is <code>1 minute</code>.</p>
  </li>
  <li><code>restart-strategy.failure-rate.delay</code>: Delay between restart attempts, used if the default restart strategy is set to “failure-rate”.
Default value is the <code>akka.ask.timeout</code>.</li>
</ul>

<h2 id="full-reference">Full Reference</h2>

<h3 id="hdfs">HDFS</h3>

<p>These parameters configure the default HDFS used by Flink. Setups that do not specify a HDFS configuration have to specify the full path to HDFS files (<code>hdfs://address:port/path/to/files</code>) Files will also be written with default HDFS parameters (block size, replication factor).</p>

<ul>
  <li>
    <p><code>fs.hdfs.hadoopconf</code>: The absolute path to the Hadoop configuration directory. The system will look for the “core-site.xml” and “hdfs-site.xml” files in that directory (DEFAULT: null).</p>
  </li>
  <li>
    <p><code>fs.hdfs.hdfsdefault</code>: The absolute path of Hadoop’s own configuration file “hdfs-default.xml” (DEFAULT: null).</p>
  </li>
  <li>
    <p><code>fs.hdfs.hdfssite</code>: The absolute path of Hadoop’s own configuration file “hdfs-site.xml” (DEFAULT: null).</p>
  </li>
</ul>

<h3 id="jobmanager-amp-taskmanager">JobManager &amp; TaskManager</h3>

<p>The following parameters configure Flink’s JobManager and TaskManagers.</p>

<ul>
  <li>
    <p><code>jobmanager.rpc.address</code>: The external address of the JobManager, which is the master/coordinator of the distributed system (DEFAULT: <strong>localhost</strong>). <strong>Note:</strong> The address (host name or IP) should be accessible by all nodes including the client.</p>
  </li>
  <li>
    <p><code>jobmanager.rpc.port</code>: The port number of the JobManager (DEFAULT: <strong>6123</strong>).</p>
  </li>
  <li>
    <p><code>taskmanager.hostname</code>: The hostname of the network interface that the TaskManager binds to. By default, the TaskManager searches for network interfaces that can connect to the JobManager and other TaskManagers. This option can be used to define a hostname if that strategy fails for some reason. Because different TaskManagers need different values for this option, it usually is specified in an additional non-shared TaskManager-specific config file.</p>
  </li>
  <li>
    <p><code>taskmanager.rpc.port</code>: The task manager’s IPC port (DEFAULT: <strong>0</strong>, which lets the OS choose a free port). Flink also accepts a list of ports (“50100,50101”), ranges (“50100-50200”) or a combination of both. It is recommended to set a range of ports to avoid collisions when multiple TaskManagers are running on the same machine.</p>
  </li>
  <li>
    <p><code>taskmanager.data.port</code>: The task manager’s port used for data exchange operations (DEFAULT: <strong>0</strong>, which lets the OS choose a free port).</p>
  </li>
  <li>
    <p><code>taskmanager.data.ssl.enabled</code>: Enable SSL support for the taskmanager data transport. This is applicable only when the global ssl flag security.ssl.enabled is set to true (DEFAULT: <strong>true</strong>)</p>
  </li>
  <li>
    <p><code>jobmanager.heap.mb</code>: JVM heap size (in megabytes) for the JobManager (DEFAULT: <strong>256</strong>).</p>
  </li>
  <li>
    <p><code>taskmanager.heap.mb</code>: JVM heap size (in megabytes) for the TaskManagers, which are the parallel workers of the system. In contrast to Hadoop, Flink runs operators (e.g., join, aggregate) and user-defined functions (e.g., Map, Reduce, CoGroup) inside the TaskManager (including sorting/hashing/caching), so this value should be as large as possible (DEFAULT: <strong>512</strong>). On YARN setups, this value is automatically configured to the size of the TaskManager’s YARN container, minus a certain tolerance value.</p>
  </li>
  <li>
    <p><code>taskmanager.numberOfTaskSlots</code>: The number of parallel operator or user function instances that a single TaskManager can run (DEFAULT: <strong>1</strong>). If this value is larger than 1, a single TaskManager takes multiple instances of a function or operator. That way, the TaskManager can utilize multiple CPU cores, but at the same time, the available memory is divided between the different operator or function instances. This value is typically proportional to the number of physical CPU cores that the TaskManager’s machine has (e.g., equal to the number of cores, or half the number of cores).</p>
  </li>
  <li>
    <p><code>taskmanager.tmp.dirs</code>: The directory for temporary files, or a list of directories separated by the system’s directory delimiter (for example ‘:’ (colon) on Linux/Unix). If multiple directories are specified, then the temporary files will be distributed across the directories in a round robin fashion. The I/O manager component will spawn one reading and one writing thread per directory. A directory may be listed multiple times to have the I/O manager use multiple threads for it (for example if it is physically stored on a very fast disc or RAID) (DEFAULT: <strong>The system’s tmp dir</strong>).</p>
  </li>
  <li>
    <p><code>taskmanager.network.memory.fraction</code>: Fraction of JVM memory to use for network buffers. This determines how many streaming data exchange channels a TaskManager can have at the same time and how well buffered the channels are. If a job is rejected or you get a warning that the system has not enough buffers available, increase this value or the min/max values below. Also note, that <code>taskmanager.network.memory.min</code> and <code>taskmanager.network.memory.max</code> may override this fraction. (DEFAULT: <strong>0.1</strong>)</p>
  </li>
  <li>
    <p><code>taskmanager.network.memory.min</code>: Minimum memory size for network buffers in bytes (DEFAULT: <strong>64 MB</strong>). Previously, this was determined from <code>taskmanager.network.numberOfBuffers</code> and <code>taskmanager.memory.segment-size</code>.</p>
  </li>
  <li>
    <p><code>taskmanager.network.memory.max</code>: Maximum memory size for network buffers in bytes (DEFAULT: <strong>1 GB</strong>). Previously, this was determined from <code>taskmanager.network.numberOfBuffers</code> and <code>taskmanager.memory.segment-size</code>.</p>
  </li>
  <li>
    <p><code>taskmanager.network.numberOfBuffers</code> (deprecated, replaced by the three parameters above): The number of buffers available to the network stack. This number determines how many streaming data exchange channels a TaskManager can have at the same time and how well buffered the channels are. If a job is rejected or you get a warning that the system has not enough buffers available, increase this value (DEFAULT: <strong>2048</strong>). If set, it will be mapped to <code>taskmanager.network.memory.min</code> and <code>taskmanager.network.memory.max</code> based on <code>taskmanager.memory.segment-size</code>.</p>
  </li>
  <li>
    <p><code>taskmanager.memory.size</code>: The amount of memory (in megabytes) that the task manager reserves on the JVM’s heap space for sorting, hash tables, and caching of intermediate results. If unspecified (-1), the memory manager will take a fixed ratio of the heap memory available to the JVM, as specified by <code>taskmanager.memory.fraction</code>. (DEFAULT: <strong>-1</strong>)</p>
  </li>
  <li>
    <p><code>taskmanager.memory.fraction</code>: The relative amount of memory (with respect to <code>taskmanager.heap.mb</code>, after subtracting the amount of memory used by network buffers) that the task manager reserves for sorting, hash tables, and caching of intermediate results. For example, a value of <code>0.8</code> means that a task manager reserves 80% of its memory (on-heap or off-heap depending on <code>taskmanager.memory.off-heap</code>) for internal data buffers, leaving 20% of free memory for the task manager’s heap for objects created by user-defined functions. (DEFAULT: 0.7) This parameter is only evaluated, if <code>taskmanager.memory.size</code> is not set.</p>
  </li>
  <li>
    <p><code>taskmanager.debug.memory.startLogThread</code>: Causes the TaskManagers to periodically log memory and Garbage collection statistics. The statistics include current heap-, off-heap, and other memory pool utilization, as well as the time spent on garbage collection, by heap memory pool.</p>
  </li>
  <li>
    <p><code>taskmanager.debug.memory.logIntervalMs</code>: The interval (in milliseconds) in which the TaskManagers log the memory and garbage collection statistics. Only has an effect, if <code>taskmanager.debug.memory.startLogThread</code> is set to true.</p>
  </li>
  <li>
    <p><code>taskmanager.maxRegistrationDuration</code>: Defines the maximum time it can take for the TaskManager registration. If the duration is exceeded without a successful registration, then the TaskManager terminates. The max registration duration requires a time unit specifier (ms/s/min/h/d) (e.g. “10 min”). (DEFAULT: <strong>Inf</strong>)</p>
  </li>
  <li>
    <p><code>taskmanager.initial-registration-pause</code>: The initial registration pause between two consecutive registration attempts. The pause is doubled for each new registration attempt until it reaches the maximum registration pause. The initial registration pause requires a time unit specifier (ms/s/min/h/d) (e.g. “5 s”). (DEFAULT: <strong>500 ms</strong>)</p>
  </li>
  <li>
    <p><code>taskmanager.max-registration-pause</code>: The maximum registration pause between two consecutive registration attempts. The max registration pause requires a time unit specifier (ms/s/min/h/d) (e.g. “5 s”). (DEFAULT: <strong>30 s</strong>)</p>
  </li>
  <li>
    <p><code>taskmanager.refused-registration-pause</code>: The pause after a registration has been refused by the job manager before retrying to connect. The refused registration pause requires a time unit specifier (ms/s/min/h/d) (e.g. “5 s”). (DEFAULT: <strong>10 s</strong>)</p>
  </li>
  <li>
    <p><code>taskmanager.jvm-exit-on-oom</code>: Indicates that the TaskManager should immediately terminate the JVM if the task thread throws an <code>OutOfMemoryError</code> (DEFAULT: <strong>false</strong>).</p>
  </li>
  <li>
    <p><code>blob.fetch.retries</code>: The number of retries for the TaskManager to download BLOBs (such as JAR files) from the JobManager (DEFAULT: <strong>50</strong>).</p>
  </li>
  <li>
    <p><code>blob.fetch.num-concurrent</code>: The number concurrent BLOB fetches (such as JAR file downloads) that the JobManager serves (DEFAULT: <strong>50</strong>).</p>
  </li>
  <li>
    <p><code>blob.fetch.backlog</code>: The maximum number of queued BLOB fetches (such as JAR file downloads) that the JobManager allows (DEFAULT: <strong>1000</strong>).</p>
  </li>
  <li>
    <p><code>task.cancellation-interval</code>: Time interval between two successive task cancellation attempts in milliseconds (DEFAULT: <strong>30000</strong>).</p>
  </li>
  <li>
    <p><code>taskmanager.exit-on-fatal-akka-error</code>: Whether the TaskManager shall be terminated in case of a fatal Akka error (quarantining event). (DEFAULT: <strong>false</strong>)</p>
  </li>
</ul>

<h3 id="distributed-coordination-via-akka">Distributed Coordination (via Akka)</h3>

<ul>
  <li>
    <p><code>akka.ask.timeout</code>: Timeout used for all futures and blocking Akka calls. If Flink fails due to timeouts then you should try to increase this value. Timeouts can be caused by slow machines or a congested network. The timeout value requires a time-unit specifier (ms/s/min/h/d) (DEFAULT: <strong>10 s</strong>).</p>
  </li>
  <li>
    <p><code>akka.lookup.timeout</code>: Timeout used for the lookup of the JobManager. The timeout value has to contain a time-unit specifier (ms/s/min/h/d) (DEFAULT: <strong>10 s</strong>).</p>
  </li>
  <li>
    <p><code>akka.client.timeout</code>: Timeout used by Flink clients (e.g. <code>CliFrontend</code>, <code>ClusterClient</code>) when communicating with the Flink cluster. The timeout value has to contain a time-unit specifier (ms/s/min/h/d) (DEFAULT: <strong>60 s</strong>).</p>
  </li>
  <li>
    <p><code>akka.framesize</code>: Maximum size of messages which are sent between the JobManager and the TaskManagers. If Flink fails because messages exceed this limit, then you should increase it. The message size requires a size-unit specifier (DEFAULT: <strong>10485760b</strong>).</p>
  </li>
  <li>
    <p><code>akka.watch.heartbeat.interval</code>: Heartbeat interval for Akka’s DeathWatch mechanism to detect dead TaskManagers. If TaskManagers are wrongly marked dead because of lost or delayed heartbeat messages, then you should increase this value. A thorough description of Akka’s DeathWatch can be found <a href="http://doc.akka.io/docs/akka/snapshot/scala/remoting.html#failure-detector">here</a> (DEFAULT: <strong>10 s</strong>).</p>
  </li>
  <li>
    <p><code>akka.watch.heartbeat.pause</code>: Acceptable heartbeat pause for Akka’s DeathWatch mechanism. A low value does not allow a irregular heartbeat. A thorough description of Akka’s DeathWatch can be found <a href="http://doc.akka.io/docs/akka/snapshot/scala/remoting.html#failure-detector">here</a> (DEFAULT: <strong>60 s</strong>).</p>
  </li>
  <li>
    <p><code>akka.watch.threshold</code>: Threshold for the DeathWatch failure detector. A low value is prone to false positives whereas a high value increases the time to detect a dead TaskManager. A thorough description of Akka’s DeathWatch can be found <a href="http://doc.akka.io/docs/akka/snapshot/scala/remoting.html#failure-detector">here</a> (DEFAULT: <strong>12</strong>).</p>
  </li>
  <li>
    <p><code>akka.transport.heartbeat.interval</code>: Heartbeat interval for Akka’s transport failure detector. Since Flink uses TCP, the detector is not necessary. Therefore, the detector is disabled by setting the interval to a very high value. In case you should need the transport failure detector, set the interval to some reasonable value. The interval value requires a time-unit specifier (ms/s/min/h/d) (DEFAULT: <strong>1000 s</strong>).</p>
  </li>
  <li>
    <p><code>akka.transport.heartbeat.pause</code>: Acceptable heartbeat pause for Akka’s transport failure detector. Since Flink uses TCP, the detector is not necessary. Therefore, the detector is disabled by setting the pause to a very high value. In case you should need the transport failure detector, set the pause to some reasonable value. The pause value requires a time-unit specifier (ms/s/min/h/d) (DEFAULT: <strong>6000 s</strong>).</p>
  </li>
  <li>
    <p><code>akka.transport.threshold</code>: Threshold for the transport failure detector. Since Flink uses TCP, the detector is not necessary and, thus, the threshold is set to a high value (DEFAULT: <strong>300</strong>).</p>
  </li>
  <li>
    <p><code>akka.tcp.timeout</code>: Timeout for all outbound connections. If you should experience problems with connecting to a TaskManager due to a slow network, you should increase this value (DEFAULT: <strong>20 s</strong>).</p>
  </li>
  <li>
    <p><code>akka.throughput</code>: Number of messages that are processed in a batch before returning the thread to the pool. Low values denote a fair scheduling whereas high values can increase the performance at the cost of unfairness (DEFAULT: <strong>15</strong>).</p>
  </li>
  <li>
    <p><code>akka.log.lifecycle.events</code>: Turns on the Akka’s remote logging of events. Set this value to ‘true’ in case of debugging (DEFAULT: <strong>false</strong>).</p>
  </li>
  <li>
    <p><code>akka.startup-timeout</code>: Timeout after which the startup of a remote component is considered being failed (DEFAULT: <strong>akka.ask.timeout</strong>).</p>
  </li>
  <li>
    <p><code>akka.ssl.enabled</code>: Turns on SSL for Akka’s remote communication. This is applicable only when the global ssl flag security.ssl.enabled is set to true (DEFAULT: <strong>true</strong>).</p>
  </li>
</ul>

<h3 id="ssl-settings">SSL Settings</h3>

<ul>
  <li>
    <p><code>security.ssl.enabled</code>: Turns on SSL for internal network communication. This can be optionally overridden by flags defined in different transport modules (DEFAULT: <strong>false</strong>).</p>
  </li>
  <li>
    <p><code>security.ssl.keystore</code>: The Java keystore file to be used by the flink endpoint for its SSL Key and Certificate.</p>
  </li>
  <li>
    <p><code>security.ssl.keystore-password</code>: The secret to decrypt the keystore file.</p>
  </li>
  <li>
    <p><code>security.ssl.key-password</code>: The secret to decrypt the server key in the keystore.</p>
  </li>
  <li>
    <p><code>security.ssl.truststore</code>: The truststore file containing the public CA certificates to be used by flink endpoints to verify the peer’s certificate.</p>
  </li>
  <li>
    <p><code>security.ssl.truststore-password</code>: The secret to decrypt the truststore.</p>
  </li>
  <li>
    <p><code>security.ssl.protocol</code>: The SSL protocol version to be supported for the ssl transport (DEFAULT: <strong>TLSv1.2</strong>). Note that it doesn’t support comma separated list.</p>
  </li>
  <li>
    <p><code>security.ssl.algorithms</code>: The comma separated list of standard SSL algorithms to be supported. Read more <a href="http://docs.oracle.com/javase/8/docs/technotes/guides/security/StandardNames.html#ciphersuites">here</a> (DEFAULT: <strong>TLS_RSA_WITH_AES_128_CBC_SHA</strong>).</p>
  </li>
  <li>
    <p><code>security.ssl.verify-hostname</code>: Flag to enable peer’s hostname verification during ssl handshake (DEFAULT: <strong>true</strong>).</p>
  </li>
</ul>

<h3 id="network-communication-via-netty">Network communication (via Netty)</h3>

<p>These parameters allow for advanced tuning. The default values are sufficient when running concurrent high-throughput jobs on a large cluster.</p>

<ul>
  <li>
    <p><code>taskmanager.net.num-arenas</code>: The number of Netty arenas (DEFAULT: <strong>taskmanager.numberOfTaskSlots</strong>).</p>
  </li>
  <li>
    <p><code>taskmanager.net.server.numThreads</code>: The number of Netty server threads (DEFAULT: <strong>taskmanager.numberOfTaskSlots</strong>).</p>
  </li>
  <li>
    <p><code>taskmanager.net.client.numThreads</code>: The number of Netty client threads (DEFAULT: <strong>taskmanager.numberOfTaskSlots</strong>).</p>
  </li>
  <li>
    <p><code>taskmanager.net.server.backlog</code>: The netty server connection backlog.</p>
  </li>
  <li>
    <p><code>taskmanager.net.client.connectTimeoutSec</code>: The Netty client connection timeout (DEFAULT: <strong>120 seconds</strong>).</p>
  </li>
  <li>
    <p><code>taskmanager.net.sendReceiveBufferSize</code>: The Netty send and receive buffer size. This defaults to the system buffer size (<code>cat /proc/sys/net/ipv4/tcp_[rw]mem</code>) and is 4 MiB in modern Linux.</p>
  </li>
  <li>
    <p><code>taskmanager.net.transport</code>: The Netty transport type, either “nio” or “epoll” (DEFAULT: <strong>nio</strong>).</p>
  </li>
</ul>

<h3 id="web-frontend">Web Frontend</h3>

<ul>
  <li>
    <p><code>web.port</code>: Port of the web interface that displays status of running jobs and execution time breakdowns of finished jobs (DEFAULT: 8081). Setting this value to <code>-1</code> disables the web frontend.</p>
  </li>
  <li>
    <p><code>web.history</code>: The number of latest jobs that the web front-end in its history (DEFAULT: 5).</p>
  </li>
  <li>
    <p><code>web.checkpoints.disable</code>: Disables checkpoint statistics (DEFAULT: <code>false</code>).</p>
  </li>
  <li>
    <p><code>web.checkpoints.history</code>: Number of checkpoint statistics to remember (DEFAULT: <code>10</code>).</p>
  </li>
  <li>
    <p><code>web.backpressure.cleanup-interval</code>: Time after which cached stats are cleaned up if not accessed (DEFAULT: <code>600000</code>, 10 mins).</p>
  </li>
  <li>
    <p><code>web.backpressure.refresh-interval</code>: Time after which available stats are deprecated and need to be refreshed (DEFAULT: <code>60000</code>, 1 min).</p>
  </li>
  <li>
    <p><code>web.backpressure.num-samples</code>: Number of stack trace samples to take to determine back pressure (DEFAULT: <code>100</code>).</p>
  </li>
  <li>
    <p><code>web.backpressure.delay-between-samples</code>: Delay between stack trace samples to determine back pressure (DEFAULT: <code>50</code>, 50 ms).</p>
  </li>
  <li>
    <p><code>web.ssl.enabled</code>: Enable https access to the web frontend. This is applicable only when the global ssl flag security.ssl.enabled is set to true (DEFAULT: <code>true</code>).</p>
  </li>
  <li>
    <p><code>web.access-control-allow-origin</code>: Enable custom access control parameter for allow origin header, default is <code>*</code>.</p>
  </li>
  <li>
    <p><code>web.timeout</code>: Timeout for asynchronous operation executed by the web frontend in milliseconds (DEFAULT: <code>10000</code>, 10 s)</p>
  </li>
</ul>

<h3 id="file-systems">File Systems</h3>

<p>The parameters define the behavior of tasks that create result files.</p>

<ul>
  <li>
    <p><code>fs.default-scheme</code>: The default filesystem scheme to be used, with the necessary authority to contact, e.g. the host:port of the NameNode in the case of HDFS (if needed).
By default, this is set to <code>file:///</code> which points to the local filesystem. This means that the local
filesystem is going to be used to search for user-specified files <strong>without</strong> an explicit scheme
definition. This scheme is used <strong>ONLY</strong> if no other scheme is specified (explicitly) in the user-provided <code>URI</code>.</p>
  </li>
  <li>
    <p><code>fs.overwrite-files</code>: Specifies whether file output writers should overwrite existing files by default. Set to <em>true</em> to overwrite by default, <em>false</em> otherwise. (DEFAULT: false)</p>
  </li>
  <li>
    <p><code>fs.output.always-create-directory</code>: File writers running with a parallelism larger than one create a directory for the output file path and put the different result files (one per parallel writer task) into that directory. If this option is set to <em>true</em>, writers with a parallelism of 1 will also create a directory and place a single result file into it. If the option is set to <em>false</em>, the writer will directly create the file directly at the output path, without creating a containing directory. (DEFAULT: false)</p>
  </li>
</ul>

<h3 id="compileroptimizer">Compiler/Optimizer</h3>

<ul>
  <li>
    <p><code>compiler.delimited-informat.max-line-samples</code>: The maximum number of line samples taken by the compiler for delimited inputs. The samples are used to estimate the number of records. This value can be overridden for a specific input with the input format’s parameters (DEFAULT: 10).</p>
  </li>
  <li>
    <p><code>compiler.delimited-informat.min-line-samples</code>: The minimum number of line samples taken by the compiler for delimited inputs. The samples are used to estimate the number of records. This value can be overridden for a specific input with the input format’s parameters (DEFAULT: 2).</p>
  </li>
  <li>
    <p><code>compiler.delimited-informat.max-sample-len</code>: The maximal length of a line sample that the compiler takes for delimited inputs. If the length of a single sample exceeds this value (possible because of misconfiguration of the parser), the sampling aborts. This value can be overridden for a specific input with the input format’s parameters (DEFAULT: 2097152 (= 2 MiBytes)).</p>
  </li>
</ul>

<h3 id="runtime-algorithms">Runtime Algorithms</h3>

<ul>
  <li>
    <p><code>taskmanager.runtime.hashjoin-bloom-filters</code>: Flag to activate/deactivate bloom filters in the hybrid hash join implementation. In cases where the hash join needs to spill to disk (datasets larger than the reserved fraction of memory), these bloom filters can greatly reduce the number of spilled records, at the cost some CPU cycles. (DEFAULT: false)</p>
  </li>
  <li>
    <p><code>taskmanager.runtime.max-fan</code>: The maximal fan-in for external merge joins and fan-out for spilling hash tables. Limits the number of file handles per operator, but may cause intermediate merging/partitioning, if set too small (DEFAULT: 128).</p>
  </li>
  <li>
    <p><code>taskmanager.runtime.sort-spilling-threshold</code>: A sort operation starts spilling when this fraction of its memory budget is full (DEFAULT: 0.8).</p>
  </li>
</ul>

<h3 id="resource-manager">Resource Manager</h3>

<p>The configuration keys in this section are independent of the used resource management framework (YARN, Mesos, Standalone, …)</p>

<ul>
  <li><code>resourcemanager.rpc.port</code>: The config parameter defining the network port to connect to for communication with the resource manager. By default, the port
of the JobManager, because the same ActorSystem is used. Its not possible to use this configuration key to define port ranges.</li>
</ul>

<h3 id="yarn">YARN</h3>

<ul>
  <li>
    <p><code>containerized.heap-cutoff-ratio</code>: (Default 0.25) Percentage of heap space to remove from containers started by YARN. When a user requests a certain amount of memory for each TaskManager container (for example 4 GB), we can not pass this amount as the maximum heap space for the JVM (<code>-Xmx</code> argument) because the JVM is also allocating memory outside the heap. YARN is very strict with killing containers which are using more memory than requested. Therefore, we remove a 15% of the memory from the requested heap as a safety margin.</p>
  </li>
  <li>
    <p><code>containerized.heap-cutoff-min</code>: (Default 600 MB) Minimum amount of memory to cut off the requested heap size.</p>
  </li>
  <li>
    <p><code>yarn.maximum-failed-containers</code> (Default: number of requested containers). Maximum number of containers the system is going to reallocate in case of a failure.</p>
  </li>
  <li>
    <p><code>yarn.application-attempts</code> (Default: 1). Number of ApplicationMaster restarts. Note that that the entire Flink cluster will restart and the YARN Client will loose the connection. Also, the JobManager address will change and you’ll need to set the JM host:port manually. It is recommended to leave this option at 1.</p>
  </li>
  <li>
    <p><code>yarn.heartbeat-delay</code> (Default: 5 seconds). Time between heartbeats with the ResourceManager.</p>
  </li>
  <li>
    <p><code>yarn.properties-file.location</code> (Default: temp directory). When a Flink job is submitted to YARN, the JobManager’s host and the number of available processing slots is written into a properties file, so that the Flink client is able to pick those details up. This configuration parameter allows changing the default location of that file (for example for environments sharing a Flink installation between users)</p>
  </li>
  <li>
    <p><code>yarn.containers.vcores</code> The number of virtual cores (vcores) per YARN container. By default, the number of <code>vcores</code> is set to the number of slots per TaskManager, if set, or to 1, otherwise.</p>
  </li>
  <li>
    <p><code>containerized.master.env.</code><em>ENV_VAR1=value</em> Configuration values prefixed with <code>containerized.master.env.</code> will be passed as environment variables to the ApplicationMaster/JobManager process. For example for passing <code>LD_LIBRARY_PATH</code> as an env variable to the ApplicationMaster, set:</p>

    <p><code>containerized.master.env.LD_LIBRARY_PATH: "/usr/lib/native"</code></p>
  </li>
  <li>
    <p><code>containerized.taskmanager.env.</code> Similar to the configuration prefix about, this prefix allows setting custom environment variables for the TaskManager processes.</p>
  </li>
  <li>
    <p><code>yarn.container-start-command-template</code>: Flink uses the following template when starting on YARN:
<code>%java% %jvmmem% %jvmopts% %logging% %class% %args% %redirects%</code>. This configuration parameter allows users
to pass custom settings (such as JVM paths, arguments etc.). Note that in most cases, it is sufficient to
use the <code>env.java.opts</code> setting, which is the <code>%jvmopts%</code> variable in the String.</p>
  </li>
  <li>
    <p><code>yarn.application-master.port</code> (Default: 0, which lets the OS choose an ephemeral port) With this configuration option, users can specify a port, a range of ports or a list of ports for the  Application Master (and JobManager) RPC port. By default we recommend using the default value (0) to let the operating system choose an appropriate port. In particular when multiple AMs are running on the  same physical host, fixed port assignments prevent the AM from starting.</p>

    <p>For example when running Flink on YARN on an environment with a restrictive firewall, this option allows specifying a range of allowed ports.</p>
  </li>
  <li>
    <p><code>yarn.tags</code> A comma-separated list of tags to apply to the Flink YARN application.</p>
  </li>
  <li>
    <p><code>yarn.per-job-cluster.include-user-jar</code> (Default: ORDER) Control whether and how the user-jar is included in the system class path for per-job clusters. Setting this parameter to <code>DISABLED</code> causes the jar to be included in the user class path instead. Setting this parameter to one of <code>FIRST</code>, <code>LAST</code> or <code>ORDER</code> causes the jar to be included in the system class path, with the jar either being placed at the beginning of the class path (<code>FIRST</code>), at the end (<code>LAST</code>), or based on the lexicographic order (<code>ORDER</code>).</p>
  </li>
</ul>

<h3 id="mesos">Mesos</h3>

<ul>
  <li>
    <p><code>mesos.initial-tasks</code>: The initial workers to bring up when the master starts (<strong>DEFAULT</strong>: The number of workers specified at cluster startup).</p>
  </li>
  <li>
    <p><code>mesos.constraints.hard.hostattribute</code>: Constraints for task placement on mesos (<strong>DEFAULT</strong>: None).</p>
  </li>
  <li>
    <p><code>mesos.maximum-failed-tasks</code>: The maximum number of failed workers before the cluster fails (<strong>DEFAULT</strong>: Number of initial workers).
May be set to -1 to disable this feature.</p>
  </li>
  <li><code>mesos.master</code>: The Mesos master URL. The value should be in one of the following forms:
    <ul>
      <li><code>host:port</code></li>
      <li><code>zk://host1:port1,host2:port2,.../path</code></li>
      <li><code>zk://username:password@host1:port1,host2:port2,.../path</code></li>
      <li><code>file:///path/to/file</code></li>
    </ul>
  </li>
  <li>
    <p><code>mesos.failover-timeout</code>: The failover timeout in seconds for the Mesos scheduler, after which running tasks are automatically shut down (<strong>DEFAULT:</strong> 600).</p>
  </li>
  <li>
    <p><code>mesos.resourcemanager.artifactserver.port</code>:The config parameter defining the Mesos artifact server port to use. Setting the port to 0 will let the OS choose an available port.</p>
  </li>
  <li>
    <p><code>mesos.resourcemanager.framework.name</code>: Mesos framework name (<strong>DEFAULT:</strong> Flink)</p>
  </li>
  <li>
    <p><code>mesos.resourcemanager.framework.role</code>: Mesos framework role definition (<strong>DEFAULT:</strong> *)</p>
  </li>
  <li>
    <p><code>mesos.resourcemanager.framework.principal</code>: Mesos framework principal (<strong>NO DEFAULT</strong>)</p>
  </li>
  <li>
    <p><code>mesos.resourcemanager.framework.secret</code>: Mesos framework secret (<strong>NO DEFAULT</strong>)</p>
  </li>
  <li>
    <p><code>mesos.resourcemanager.framework.user</code>: Mesos framework user (<strong>DEFAULT:</strong>””)</p>
  </li>
  <li>
    <p><code>mesos.resourcemanager.artifactserver.ssl.enabled</code>: Enables SSL for the Flink artifact server (<strong>DEFAULT</strong>: true). Note that <code>security.ssl.enabled</code> also needs to be set to <code>true</code> encryption to enable encryption.</p>
  </li>
  <li>
    <p><code>mesos.resourcemanager.tasks.mem</code>: Memory to assign to the Mesos workers in MB (<strong>DEFAULT</strong>: 1024)</p>
  </li>
  <li>
    <p><code>mesos.resourcemanager.tasks.cpus</code>: CPUs to assign to the Mesos workers (<strong>DEFAULT</strong>: 0.0)</p>
  </li>
  <li>
    <p><code>mesos.resourcemanager.tasks.container.type</code>: Type of the containerization used: “mesos” or “docker” (DEFAULT: mesos);</p>
  </li>
  <li>
    <p><code>mesos.resourcemanager.tasks.container.image.name</code>: Image name to use for the container (<strong>NO DEFAULT</strong>)</p>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td><code>mesos.resourcemanager.tasks.container.volumes</code>: A comma seperated list of [host_path:]container_path[:RO</td>
          <td>RW]. This allows for mounting additional volumes into your container. (<strong>NO DEFAULT</strong>)</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li><code>high-availability.zookeeper.path.mesos-workers</code>: The ZooKeeper root path for persisting the Mesos worker information.</li>
</ul>

<h3 id="high-availability-ha">High Availability (HA)</h3>

<ul>
  <li><code>high-availability</code>: Defines the high availability mode used for the cluster execution. Currently, Flink supports the following modes:
    <ul>
      <li><code>none</code> (default): No high availability. A single JobManager runs and no JobManager state is checkpointed.</li>
      <li><code>zookeeper</code>: Supports the execution of multiple JobManagers and JobManager state checkpointing. Among the group of JobManagers, ZooKeeper elects one of them as the leader which is responsible for the cluster execution. In case of a JobManager failure, a standby JobManager will be elected as the new leader and is given the last checkpointed JobManager state. In order to use the ‘zookeeper’ mode, it is mandatory to also define the <code>high-availability.zookeeper.quorum</code> configuration value.</li>
    </ul>
  </li>
  <li><code>high-availability.cluster-id</code>: (Default <code>/default_ns</code> in standalone cluster mode, or the <yarn-application-id> under YARN) Defines the subdirectory under the root dir where the ZooKeeper HA mode will create znodes. This allows to isolate multiple applications on the same ZooKeeper. Previously this key was named `recovery.zookeeper.path.namespace` and `high-availability.zookeeper.path.namespace`.</yarn-application-id></li>
</ul>

<p>Previously this key was named <code>recovery.mode</code> and the default value was <code>standalone</code>.</p>

<h4 id="zookeeper-based-ha-mode">ZooKeeper-based HA Mode</h4>

<ul>
  <li>
    <p><code>high-availability.zookeeper.quorum</code>: Defines the ZooKeeper quorum URL which is used to connect to the ZooKeeper cluster when the ‘zookeeper’ HA mode is selected. Previously this key was named <code>recovery.zookeeper.quorum</code>.</p>
  </li>
  <li>
    <p><code>high-availability.zookeeper.path.root</code>: (Default <code>/flink</code>) Defines the root dir under which the ZooKeeper HA mode will create namespace directories. Previously this ket was named <code>recovery.zookeeper.path.root</code>.</p>
  </li>
  <li>
    <p><code>high-availability.zookeeper.path.latch</code>: (Default <code>/leaderlatch</code>) Defines the znode of the leader latch which is used to elect the leader. Previously this key was named <code>recovery.zookeeper.path.latch</code>.</p>
  </li>
  <li>
    <p><code>high-availability.zookeeper.path.leader</code>: (Default <code>/leader</code>) Defines the znode of the leader which contains the URL to the leader and the current leader session ID. Previously this key was named <code>recovery.zookeeper.path.leader</code>.</p>
  </li>
  <li>
    <p><code>high-availability.storageDir</code>: Defines the directory in the state backend where the JobManager metadata will be stored (ZooKeeper only keeps pointers to it). Required for HA. Previously this key was named <code>recovery.zookeeper.storageDir</code> and <code>high-availability.zookeeper.storageDir</code>.</p>
  </li>
  <li>
    <p><code>high-availability.zookeeper.client.session-timeout</code>: (Default <code>60000</code>) Defines the session timeout for the ZooKeeper session in ms. Previously this key was named <code>recovery.zookeeper.client.session-timeout</code></p>
  </li>
  <li>
    <p><code>high-availability.zookeeper.client.connection-timeout</code>: (Default <code>15000</code>) Defines the connection timeout for ZooKeeper in ms. Previously this key was named <code>recovery.zookeeper.client.connection-timeout</code>.</p>
  </li>
  <li>
    <p><code>high-availability.zookeeper.client.retry-wait</code>: (Default <code>5000</code>) Defines the pause between consecutive retries in ms. Previously this key was named <code>recovery.zookeeper.client.retry-wait</code>.</p>
  </li>
  <li>
    <p><code>high-availability.zookeeper.client.max-retry-attempts</code>: (Default <code>3</code>) Defines the number of connection retries before the client gives up. Previously this key was named <code>recovery.zookeeper.client.max-retry-attempts</code>.</p>
  </li>
  <li>
    <p><code>high-availability.job.delay</code>: (Default <code>akka.ask.timeout</code>) Defines the delay before persisted jobs are recovered in case of a master recovery situation. Previously this key was named <code>recovery.job.delay</code>.</p>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td><code>high-availability.zookeeper.client.acl</code>: (Default <code>open</code>) Defines the ACL (open</td>
          <td>creator) to be configured on ZK node. The configuration value can be set to “creator” if the ZooKeeper server configuration has the “authProvider” property mapped to use SASLAuthenticationProvider and the cluster is configured to run in secure mode (Kerberos). The ACL options are based on https://zookeeper.apache.org/doc/r3.1.2/zookeeperProgrammers.html#sc_BuiltinACLSchemes</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<h4 id="zookeeper-security">ZooKeeper Security</h4>

<ul>
  <li>
    <p><code>zookeeper.sasl.disable</code>: (Default: <code>true</code>) Defines if SASL based authentication needs to be enabled or disabled. The configuration value can be set to “true” if ZooKeeper cluster is running in secure mode (Kerberos).</p>
  </li>
  <li>
    <p><code>zookeeper.sasl.service-name</code>: (Default: <code>zookeeper</code>) If the ZooKeeper server is configured with a different service name (default:”zookeeper”) then it can be supplied using this configuration. A mismatch in service name between client and server configuration will cause the authentication to fail.</p>
  </li>
</ul>

<h3 id="kerberos-based-security-1">Kerberos-based Security</h3>

<ul>
  <li>
    <p><code>security.kerberos.login.use-ticket-cache</code>: Indicates whether to read from your Kerberos ticket cache (default: <code>true</code>).</p>
  </li>
  <li>
    <p><code>security.kerberos.login.keytab</code>: Absolute path to a Kerberos keytab file that contains the user credentials.</p>
  </li>
  <li>
    <p><code>security.kerberos.login.principal</code>: Kerberos principal name associated with the keytab.</p>
  </li>
  <li>
    <p><code>security.kerberos.login.contexts</code>: A comma-separated list of login contexts to provide the Kerberos credentials to (for example, <code>Client,KafkaClient</code> to use the credentials for ZooKeeper authentication and for Kafka authentication).</p>
  </li>
</ul>

<h3 id="environment">Environment</h3>

<ul>
  <li>
    <p><code>env.log.dir</code>: (Defaults to the <code>log</code> directory under Flink’s home) Defines the directory where the Flink logs are saved. It has to be an absolute path.</p>
  </li>
  <li>
    <p><code>env.log.max</code>: (Default: <code>5</code>) The maximum number of old log files to keep.</p>
  </li>
  <li>
    <p><code>env.ssh.opts</code>: Additional command line options passed to SSH clients when starting or stopping JobManager, TaskManager, and Zookeeper services (start-cluster.sh, stop-cluster.sh, start-zookeeper-quorum.sh, stop-zookeeper-quorum.sh).</p>
  </li>
</ul>

<h3 id="queryable-state">Queryable State</h3>

<h4 id="server">Server</h4>

<ul>
  <li>
    <p><code>query.server.enable</code>: Enable queryable state (Default: <code>true</code>).</p>
  </li>
  <li>
    <p><code>query.server.port</code>: Port to bind queryable state server to (Default: <code>0</code>, binds to random port).</p>
  </li>
  <li>
    <p><code>query.server.network-threads</code>: Number of network (Netty’s event loop) Threads for queryable state server (Default: <code>0</code>, picks number of slots).</p>
  </li>
  <li>
    <p><code>query.server.query-threads</code>: Number of query Threads for queryable state server (Default: <code>0</code>, picks number of slots).</p>
  </li>
</ul>

<h4 id="client">Client</h4>

<ul>
  <li>
    <p><code>query.client.network-threads</code>: Number of network (Netty’s event loop) Threads for queryable state client (Default: <code>0</code>, picks number of available cores as returned by <code>Runtime.getRuntime().availableProcessors()</code>).</p>
  </li>
  <li>
    <p><code>query.client.lookup.num-retries</code>: Number of retries on KvState lookup failure due to unavailable JobManager (Default: <code>3</code>).</p>
  </li>
  <li>
    <p><code>query.client.lookup.retry-delay</code>: Retry delay in milliseconds on KvState lookup failure due to unavailable JobManager (Default: <code>1000</code>).</p>
  </li>
</ul>

<h3 id="metrics">Metrics</h3>

<ul>
  <li>
    <p><code>metrics.reporters</code>: The list of named reporters, i.e. “foo,bar”.</p>
  </li>
  <li>
    <p><code>metrics.reporter.&lt;name&gt;.&lt;config&gt;</code>: Generic setting <code>&lt;config&gt;</code> for the reporter named <code>&lt;name&gt;</code>.</p>
  </li>
  <li>
    <p><code>metrics.reporter.&lt;name&gt;.class</code>: The reporter class to use for the reporter named <code>&lt;name&gt;</code>.</p>
  </li>
  <li>
    <p><code>metrics.reporter.&lt;name&gt;.interval</code>: The reporter interval to use for the reporter named <code>&lt;name&gt;</code>.</p>
  </li>
  <li>
    <p><code>metrics.scope.jm</code>: (Default: &lt;host&gt;.jobmanager) Defines the scope format string that is applied to all metrics scoped to a JobManager.</p>
  </li>
  <li>
    <p><code>metrics.scope.jm.job</code>: (Default: &lt;host&gt;.jobmanager.&lt;job_name&gt;) Defines the scope format string that is applied to all metrics scoped to a job on a JobManager.</p>
  </li>
  <li>
    <p><code>metrics.scope.tm</code>: (Default: &lt;host&gt;.taskmanager.&lt;tm_id&gt;) Defines the scope format string that is applied to all metrics scoped to a TaskManager.</p>
  </li>
  <li>
    <p><code>metrics.scope.tm.job</code>: (Default: &lt;host&gt;.taskmanager.&lt;tm_id&gt;.&lt;job_name&gt;) Defines the scope format string that is applied to all metrics scoped to a job on a TaskManager.</p>
  </li>
  <li>
    <p><code>metrics.scope.task</code>: (Default: &lt;host&gt;.taskmanager.&lt;tm_id&gt;.&lt;job_name&gt;.&lt;task_name&gt;.&lt;subtask_index&gt;) Defines the scope format string that is applied to all metrics scoped to a task.</p>
  </li>
  <li>
    <p><code>metrics.scope.operator</code>: (Default: &lt;host&gt;.taskmanager.&lt;tm_id&gt;.&lt;job_name&gt;.&lt;operator_name&gt;.&lt;subtask_index&gt;) Defines the scope format string that is applied to all metrics scoped to an operator.</p>
  </li>
  <li>
    <p><code>metrics.latency.history-size</code>: (Default: 128) Defines the number of measured latencies to maintain at each operator</p>
  </li>
</ul>

<h3 id="history-server">History Server</h3>

<p>You have to configure <code>jobmanager.archive.fs.dir</code> in order to archive terminated jobs and add it to the list of monitored directories via <code>historyserver.archive.fs.dir</code> if you want to display them via the HistoryServer’s web frontend.</p>

<ul>
  <li>
    <p><code>jobmanager.archive.fs.dir</code>: Directory to upload information about terminated jobs to. You have to add this directory to the list of monitored directories of the history server via <code>historyserver.archive.fs.dir</code>.</p>
  </li>
  <li>
    <p><code>historyserver.archive.fs.dir</code>: Comma separated list of directories to fetch archived jobs from. The history server will monitor these directories for archived jobs. You can configure the JobManager to archive jobs to a directory via <code>jobmanager.archive.fs.dir</code>.</p>
  </li>
  <li>
    <p><code>historyserver.archive.fs.refresh-interval</code>: Interval in milliseconds for refreshing the archived job directories (DEFAULT: <code>10000</code>).</p>
  </li>
  <li>
    <p><code>historyserver.web.tmpdir</code>: This configuration parameter allows defining the Flink web directory to be used by the history server web interface. The web interface will copy its static files into the directory (DEFAULT: local system temporary directory).</p>
  </li>
  <li>
    <p><code>historyserver.web.address</code>: Address of the HistoryServer’s web interface (DEFAULT: <code>anyLocalAddress()</code>).</p>
  </li>
  <li>
    <p><code>historyserver.web.port</code>: Port of the HistoryServers’s web interface (DEFAULT: <code>8082</code>).</p>
  </li>
  <li>
    <p><code>historyserver.web.ssl.enabled</code>: Enable HTTPs access to the HistoryServer web frontend. This is applicable only when the global SSL flag security.ssl.enabled is set to true (DEFAULT: <code>false</code>).</p>
  </li>
</ul>

<h2 id="background">Background</h2>

<h3 id="configuring-the-network-buffers">Configuring the Network Buffers</h3>

<p>If you ever see the Exception <code>java.io.IOException: Insufficient number of network buffers</code>, you
need to adapt the amount of memory used for network buffers in order for your program to run on your
task managers.</p>

<p>Network buffers are a critical resource for the communication layers. They are used to buffer
records before transmission over a network, and to buffer incoming data before dissecting it into
records and handing them to the application. A sufficient number of network buffers is critical to
achieve a good throughput.</p>

<div class="alert alert-info">
Since Flink 1.3, you may follow the idiom "more is better" without any penalty on the latency (we
prevent excessive buffering in each outgoing and incoming channel, i.e. *buffer bloat*, by limiting
the actual number of buffers used by each channel).
</div>

<p>In general, configure the task manager to have enough buffers that each logical network connection
you expect to be open at the same time has a dedicated buffer. A logical network connection exists
for each point-to-point exchange of data over the network, which typically happens at
repartitioning or broadcasting steps (shuffle phase). In those, each parallel task inside the
TaskManager has to be able to talk to all other parallel tasks.</p>

<h4 id="setting-memory-fractions">Setting Memory Fractions</h4>

<p>Previously, the number of network buffers was set manually which became a quite error-prone task
(see below). Since Flink 1.3, it is possible to define a fraction of memory that is being used for
network buffers with the following configuration parameters:</p>

<ul>
  <li><code>taskmanager.network.memory.fraction</code>: Fraction of JVM memory to use for network buffers (DEFAULT: 0.1),</li>
  <li><code>taskmanager.network.memory.min</code>: Minimum memory size for network buffers in bytes (DEFAULT: 64 MB),</li>
  <li><code>taskmanager.network.memory.max</code>: Maximum memory size for network buffers in bytes (DEFAULT: 1 GB), and</li>
  <li><code>taskmanager.memory.segment-size</code>: Size of memory buffers used by the memory manager and the
network stack in bytes (DEFAULT: 32768 (= 32 KiBytes)).</li>
</ul>

<h4 id="setting-the-number-of-network-buffers-directly">Setting the Number of Network Buffers directly</h4>

<div class="alert alert-warning">
  <strong>Note:</strong> This way of configuring the amount of memory used for network buffers is deprecated. Please consider using the method above by defining a fraction of memory to use.
</div>

<p>The required number of buffers on a task manager is
<em>total-degree-of-parallelism</em> (number of targets) * <em>intra-node-parallelism</em> (number of sources in one task manager) * <em>n</em>
with <em>n</em> being a constant that defines how many repartitioning-/broadcasting steps you expect to be
active at the same time. Since the <em>intra-node-parallelism</em> is typically the number of cores, and
more than 4 repartitioning or broadcasting channels are rarely active in parallel, it frequently
boils down to</p>

<div class="highlight"><pre><code>#slots-per-TM^2 * #TMs * 4
</code></pre></div>

<p>Where <code>#slots per TM</code> are the <a href="#configuring-taskmanager-processing-slots">number of slots per TaskManager</a> and <code>#TMs</code> are the total number of task managers.</p>

<p>To support, for example, a cluster of 20 8-slot machines, you should use roughly 5000 network
buffers for optimal throughput.</p>

<p>Each network buffer has by default a size of 32 KiBytes. In the example above, the system would thus
allocate roughly 300 MiBytes for network buffers.</p>

<p>The number and size of network buffers can be configured with the following parameters:</p>

<ul>
  <li><code>taskmanager.network.numberOfBuffers</code>, and</li>
  <li><code>taskmanager.memory.segment-size</code>.</li>
</ul>

<h3 id="configuring-temporary-io-directories">Configuring Temporary I/O Directories</h3>

<p>Although Flink aims to process as much data in main memory as possible, it is not uncommon that more data needs to be processed than memory is available. Flink’s runtime is designed to write temporary data to disk to handle these situations.</p>

<p>The <code>taskmanager.tmp.dirs</code> parameter specifies a list of directories into which Flink writes temporary files. The paths of the directories need to be separated by ‘:’ (colon character). Flink will concurrently write (or read) one temporary file to (from) each configured directory. This way, temporary I/O can be evenly distributed over multiple independent I/O devices such as hard disks to improve performance. To leverage fast I/O devices (e.g., SSD, RAID, NAS), it is possible to specify a directory multiple times.</p>

<p>If the <code>taskmanager.tmp.dirs</code> parameter is not explicitly specified, Flink writes temporary data to the temporary directory of the operating system, such as <em>/tmp</em> in Linux systems.</p>

<h3 id="configuring-taskmanager-processing-slots">Configuring TaskManager processing slots</h3>

<p>Flink executes a program in parallel by splitting it into subtasks and scheduling these subtasks to processing slots.</p>

<p>Each Flink TaskManager provides processing slots in the cluster. The number of slots is typically proportional to the number of available CPU cores <strong>of each</strong> TaskManager. As a general recommendation, the number of available CPU cores is a good default for <code>taskmanager.numberOfTaskSlots</code>.</p>

<p>When starting a Flink application, users can supply the default number of slots to use for that job. The command line value therefore is called <code>-p</code> (for parallelism). In addition, it is possible to <a href="//ci.apache.org/projects/flink/flink-docs-release-1.4/dev/parallel.html">set the number of slots in the programming APIs</a> for the whole application and for individual operators.</p>

<p><img src="//ci.apache.org/projects/flink/flink-docs-release-1.4/fig/slots_parallelism.svg" class="img-responsive" /></p>


        </div>
      </div>
    </div><!-- /.container -->

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/3.1.0/anchor.min.js"></script>
    <script src="//ci.apache.org/projects/flink/flink-docs-release-1.4/page/js/flink.js"></script>

    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-52545728-1', 'auto');
      ga('send', 'pageview');
    </script>

    <!-- Disqus -->
    
  </body>
</html>
